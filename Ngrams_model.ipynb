{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language models using Ngrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Brungesh BE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will explore language models.\n",
    "To do so, we will encapsulate a language model using a class called `language_model` which implements language models with Laplace add-one smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "class language_model:\n",
    "\n",
    "    def __init__(self, ngram=1):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize a language model\n",
    "\n",
    "        Parameters:\n",
    "        ngram specifies the type of model:  \n",
    "        unigram (ngram = 1), bigram (ngram = 2) etc.\n",
    "        \"\"\"\n",
    "        self.ngram = ngram\n",
    "\n",
    "    def unigram(self, text):\n",
    "        \n",
    "        \"\"\"Calculate the unigram counts for the file \n",
    "        and store them in a dictionary\"\"\"\n",
    "        \n",
    "        data = {}\n",
    "        words = [word for sentence in text for word in sentence.split()]\n",
    "        word_length = len(set(words))\n",
    "        self.c = Counter(words)\n",
    "\n",
    "        for word in words:\n",
    "            data[word] = (self.c[word] / word_length)\n",
    "        return data, word_length\n",
    "\n",
    "    def text_clean(self, text):\n",
    "        \n",
    "        \"\"\" Clean the text for special characters and add begining and \n",
    "        ending sentence tokens to each sentence\"\"\"\n",
    "        \n",
    "        text = text.strip('\\n').lower()\n",
    "        text = text.replace('\\n', ' ')\n",
    "\n",
    "        text = text.translate ({ord(c): \".\" for c in \"!:?\"})\n",
    "        text = text.translate ({ord(c): \"\" for c in \"\\\"\\''\"\"@#$%^&*()[]{};,/<>\\|`~=_+\"})\n",
    "        text = text.translate ({ord(c): \" \" for c in \"-\"})\n",
    "\n",
    "        sentences = ['<s> ' +\" \".join(sentence.split())+ ' </s>' for sentence in text.split('.') if sentence != \"\"]\n",
    "        return sentences\n",
    "\n",
    "    def ngram_generation(self, sentence, n):\n",
    "        \n",
    "        \"\"\"Generate ngrams for each sentence\"\"\"\n",
    "        \n",
    "        tokens = [token for token in sentence.split(\" \") if token != \"\"]\n",
    "        ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "        ngrams = [\" \".join(ngram) for ngram in ngrams]\n",
    "        ngrams = [tuple(sent.split()) for sent in ngrams]\n",
    "        return ngrams\n",
    "\n",
    "    def bigram(self, text):\n",
    "        \n",
    "        \"\"\"Calculate the bigram counts for the file \n",
    "        and store them in a model\"\"\"\n",
    "        \n",
    "        model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        for sentence in text:\n",
    "            for w1, w2 in self.ngram_generation(sentence, 2):\n",
    "                model[(w1)][w2] += 1\n",
    "        for w1 in model:\n",
    "            total_count = self.c[w1]\n",
    "            for w2 in model[w1]:\n",
    "                model[w1][w2] /= total_count\n",
    "        return model\n",
    "\n",
    "    def trigram(self, text):\n",
    "        \n",
    "        \"\"\"Calculate the trigram counts for the file \n",
    "        and store them in a model\"\"\"\n",
    "        \n",
    "        model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        for sentence in text:\n",
    "            for w1, w2, w3 in self.ngram_generation(sentence, 3):\n",
    "                model[(w1, w2)][w3] += 1\n",
    "        for w1_w2 in model:\n",
    "            total_count = self.bi_data[w1_w2]\n",
    "            for w3 in model[w1_w2]:\n",
    "                model[w1_w2][w3] /= total_count\n",
    "        return model\n",
    "    \n",
    "    def perplexity(self, data):\n",
    "        \n",
    "        \"\"\"Calculate perplexity for the corpus\"\"\"\n",
    "        \n",
    "        exp = [np.log2(v) for k,v in data.items()]\n",
    "        exp = sum(exp) / len(exp)\n",
    "        return np.power(2, -exp)\n",
    "\n",
    "\n",
    "    def train(self, file_name) :\n",
    "        \"\"\"\n",
    "        train a language model\n",
    "\n",
    "        Parameters:\n",
    "        file_name is a file that contains the training set for the model\n",
    "        \"\"\"\n",
    "        with open(file_name, 'r') as f:\n",
    "            text = f.read()\n",
    "        clean_text = self.text_clean(text)\n",
    "\n",
    "        if self.ngram == 1:\n",
    "            self.uni_data, self.uni_count = self.unigram(clean_text)\n",
    "        if self.ngram == 2:\n",
    "            self.uni_data, self.uni_count = self.unigram(clean_text)\n",
    "            bi_model = dict(self.bigram(clean_text))\n",
    "            self.bi_data = {(i,j): bi_model[i][j] \n",
    "                                       for i in bi_model.keys() \n",
    "                                       for j in bi_model[i].keys()}\n",
    "            self.bi_data_count = len(self.bi_data)\n",
    "\n",
    "        if self.ngram == 3:\n",
    "            self.uni_data, self.uni_count = self.unigram(clean_text)\n",
    "            bi_model = dict(self.bigram(clean_text))\n",
    "            self.bi_data = {(i,j): bi_model[i][j] \n",
    "                                       for i in bi_model.keys() \n",
    "                                       for j in bi_model[i].keys()}\n",
    "            self.bi_data_count = len(self.bi_data)\n",
    "            tri_model = dict(self.trigram(clean_text))\n",
    "            self.tri_data = {(i,j): tri_model[i][j] \n",
    "                                       for i in tri_model.keys() \n",
    "                                       for j in tri_model[i].keys()}\n",
    "            new_dict = {}\n",
    "            for k,v in self.tri_data.items():\n",
    "                tup = []\n",
    "                tup = [tupl for tupl in k[0]]\n",
    "                tup.append(k[1])\n",
    "                new_dict[tuple(tup)] = v\n",
    "            self.tri_data = new_dict\n",
    "            self.tri_data_count = len(self.tri_data)\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def test(self, file_name) :\n",
    "        \"\"\"\n",
    "        Test a language model on a given text and return the perplexity \n",
    "        of a trained model on the text provided as input\n",
    "\n",
    "        Parameters:\n",
    "        file_name is a file that contains the test set on which the \n",
    "        model needs to be evaluated \n",
    "        \"\"\"\n",
    "        with open(file_name, 'r') as f:\n",
    "            test_text = f.read()\n",
    "        clean_test_text = self.text_clean(test_text)\n",
    "        test_dict = {}\n",
    "        self.zero_count = 0\n",
    "        self.sparsity = 0\n",
    "\n",
    "        if self.ngram == 1:\n",
    "            for sentence in clean_test_text:\n",
    "                for word in sentence.split():\n",
    "                    if word not in self.uni_data.keys():\n",
    "                        test_dict[word] = 1/self.uni_count\n",
    "                        self.zero_count += 1\n",
    "                    else:\n",
    "                        test_dict[word] = self.uni_data[word]\n",
    "            if self.zero_count:\n",
    "                self.sparsity = self.zero_count/len(test_dict)\n",
    "\n",
    "        if self.ngram == 2:\n",
    "            for sentence in clean_test_text:\n",
    "                for word in self.ngram_generation(sentence, self.ngram):\n",
    "                    if word not in self.bi_data.keys():\n",
    "                        test_dict[word] = 1/self.bi_data_count\n",
    "                        self.zero_count += 1\n",
    "                    else:\n",
    "                        test_dict[word] = self.bi_data[word]\n",
    "            if self.zero_count:\n",
    "                self.sparsity = self.zero_count/len(test_dict)\n",
    "                        \n",
    "        if self.ngram == 3:\n",
    "            for sentence in clean_test_text:\n",
    "                for word in self.ngram_generation(sentence, self.ngram):\n",
    "                    if word not in self.tri_data.keys():\n",
    "                        test_dict[word] = 1/self.tri_data_count\n",
    "                        self.zero_count += 1\n",
    "                    else:\n",
    "                        test_dict[word] = self.tri_data[word]\n",
    "            if self.zero_count:\n",
    "                self.sparsity = self.zero_count/len(test_dict)\n",
    "\n",
    "        return self.perplexity(test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2080.9480738645634"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = language_model(1)\n",
    "lm.train(\"pride_and_prejudice.txt\")\n",
    "lm.test(\"persuasion.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6168.125846028626"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = language_model(2)\n",
    "lm.train(\"pride_and_prejudice.txt\")\n",
    "lm.test(\"persuasion.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13876.31400073753"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = language_model(3)\n",
    "lm.train(\"pride_and_prejudice.txt\")\n",
    "lm.test(\"persuasion.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results we can say that unigram, bigram and trigram perform differently for the same set of train and test data. As seen, the perplexity increases as ngram increases. Since lower perpelxity results in better model performance we can say that the unigram has the best performance. But it also depends on the data points distribution in the dataset. If we train for a different dataset the results may vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabulations of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>Author</th>\n",
       "      <th>Book</th>\n",
       "      <th>Perplexity</th>\n",
       "      <th>Sparsity</th>\n",
       "      <th>Zero counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jane Aysten</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>1946.746583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jane Aysten</td>\n",
       "      <td>Persuasion</td>\n",
       "      <td>2080.948074</td>\n",
       "      <td>0.840722</td>\n",
       "      <td>4893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jane Aysten</td>\n",
       "      <td>Sense and Sensibility</td>\n",
       "      <td>2196.610014</td>\n",
       "      <td>1.024134</td>\n",
       "      <td>6535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Charlotte Bronte</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>3727.991643</td>\n",
       "      <td>1.715938</td>\n",
       "      <td>21662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Lewis Carroll</td>\n",
       "      <td>Alice in Wonderland</td>\n",
       "      <td>1064.934993</td>\n",
       "      <td>0.760740</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane Aysten</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>57.544191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane Aysten</td>\n",
       "      <td>Persuasion</td>\n",
       "      <td>6168.125846</td>\n",
       "      <td>0.834767</td>\n",
       "      <td>34268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane Aysten</td>\n",
       "      <td>Sense and Sensibility</td>\n",
       "      <td>6347.809378</td>\n",
       "      <td>0.874780</td>\n",
       "      <td>46212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>Charlotte Bronte</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>16524.004566</td>\n",
       "      <td>1.083011</td>\n",
       "      <td>97849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Lewis Carroll</td>\n",
       "      <td>Alice in Wonderland</td>\n",
       "      <td>4305.634340</td>\n",
       "      <td>0.787002</td>\n",
       "      <td>4977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>Jane Aysten</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>0.018356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>Jane Aysten</td>\n",
       "      <td>Persuasion</td>\n",
       "      <td>13876.314001</td>\n",
       "      <td>0.937856</td>\n",
       "      <td>66373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>Jane Aysten</td>\n",
       "      <td>Sense and Sensibility</td>\n",
       "      <td>13522.628100</td>\n",
       "      <td>0.948902</td>\n",
       "      <td>93389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>Charlotte Bronte</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>35475.469181</td>\n",
       "      <td>1.032362</td>\n",
       "      <td>160904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>Lewis Carroll</td>\n",
       "      <td>Alice in Wonderland</td>\n",
       "      <td>12850.821125</td>\n",
       "      <td>0.955507</td>\n",
       "      <td>8268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ngram            Author                   Book    Perplexity  Sparsity  \\\n",
       "0       1       Jane Aysten    Pride and Prejudice   1946.746583  0.000000   \n",
       "1       1       Jane Aysten             Persuasion   2080.948074  0.840722   \n",
       "2       1       Jane Aysten  Sense and Sensibility   2196.610014  1.024134   \n",
       "3       1  Charlotte Bronte              Jane Eyre   3727.991643  1.715938   \n",
       "4       1     Lewis Carroll    Alice in Wonderland   1064.934993  0.760740   \n",
       "5       2       Jane Aysten    Pride and Prejudice     57.544191  0.000000   \n",
       "6       2       Jane Aysten             Persuasion   6168.125846  0.834767   \n",
       "7       2       Jane Aysten  Sense and Sensibility   6347.809378  0.874780   \n",
       "8       2  Charlotte Bronte              Jane Eyre  16524.004566  1.083011   \n",
       "9       2     Lewis Carroll    Alice in Wonderland   4305.634340  0.787002   \n",
       "10      3       Jane Aysten    Pride and Prejudice      0.018356  0.000000   \n",
       "11      3       Jane Aysten             Persuasion  13876.314001  0.937856   \n",
       "12      3       Jane Aysten  Sense and Sensibility  13522.628100  0.948902   \n",
       "13      3  Charlotte Bronte              Jane Eyre  35475.469181  1.032362   \n",
       "14      3     Lewis Carroll    Alice in Wonderland  12850.821125  0.955507   \n",
       "\n",
       "    Zero counts  \n",
       "0             0  \n",
       "1          4893  \n",
       "2          6535  \n",
       "3         21662  \n",
       "4          1151  \n",
       "5             0  \n",
       "6         34268  \n",
       "7         46212  \n",
       "8         97849  \n",
       "9          4977  \n",
       "10            0  \n",
       "11        66373  \n",
       "12        93389  \n",
       "13       160904  \n",
       "14         8268  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result = []\n",
    "for n in range(1,4):\n",
    "    l = language_model(n)\n",
    "    l.train(\"pride_and_prejudice.txt\")\n",
    "    result.append([l.ngram, \"Jane Aysten\", \"Pride and Prejudice\", l.test(\"pride_and_prejudice.txt\"), l.sparsity, l.zero_count])\n",
    "    result.append([l.ngram, \"Jane Aysten\", \"Persuasion\", l.test(\"persuasion.txt\"), l.sparsity, l.zero_count])\n",
    "    result.append([l.ngram, \"Jane Aysten\", \"Sense and Sensibility\", l.test(\"sense_and_sensibility.txt\"), l.sparsity, l.zero_count])\n",
    "    result.append([l.ngram, \"Charlotte Bronte\", \"Jane Eyre\", l.test(\"jane_eyre.txt\"), l.sparsity, l.zero_count])\n",
    "    result.append([l.ngram, \"Lewis Carroll\", \"Alice in Wonderland\", l.test(\"alice_in_wonderland.txt\"), l.sparsity, l.zero_count])\n",
    "result\n",
    "\n",
    "df = pd.DataFrame(result, columns = ['ngram', 'Author', 'Book', 'Perplexity', 'Sparsity', 'Zero counts'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Language model has been trained with the prisde and prejudice dataset and tested for the rest of the books written by Jane as well as other contemporaries. The sparsity of the bigram and trigram models depends on how many data points we have for the particular dataset. The higher the ngram higher is the sparsity of the model. The fraction of zero counts in the dataset before smoothing can be observed in the table. Testing on different authors gives more zero counts since there's a drastic change in the style of contemporary writings of different authors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
